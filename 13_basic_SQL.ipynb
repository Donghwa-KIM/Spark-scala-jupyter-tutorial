{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparkSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read/write json이 사용될 수 있음\n",
    "- spark session(SparkContext, SqlContext)이 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://163.152.185.244:4041\n",
       "SparkContext available as 'sc' (version = 2.3.1, master = local[*], app id = local-1554313599365)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark._\n",
       "import org.apache.spark.SparkContext._\n",
       "import org.apache.spark.sql._\n",
       "import org.apache.log4j._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.sql._\n",
    "import spark.implicits._ // RDD to table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```scala\n",
    "case class Person(ID:Int, name:String, age:Int, numFriends:Int)\n",
    "```\n",
    "- 먼저 RDD로 불러와 데이터 프레임의 column이름을 정의할때 case class와 map을 이용하여 table을 만들 수 있음\n",
    "- case class: simple class in scala\n",
    "- notebook에서는 이러한 방식이 job할당이 잘 안됨\n",
    "- 대안으로 사전에 이름을 정의하여 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType}\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID: org.apache.spark.sql.types.StructField = StructField(ID,IntegerType,true)\n",
       "name: org.apache.spark.sql.types.StructField = StructField(name,StringType,true)\n",
       "age: org.apache.spark.sql.types.StructField = StructField(age,IntegerType,true)\n",
       "num: org.apache.spark.sql.types.StructField = StructField(numFriends,IntegerType,true)\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(ID,IntegerType,true), StructField(name,StringType,true), StructField(age,IntegerType,true), StructField(numFriends,IntegerType,true))\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ID = StructField(\"ID\", IntegerType)\n",
    "val name = StructField(\"name\", StringType)\n",
    "val age = StructField(\"age\", IntegerType)\n",
    "val num = StructField(\"numFriends\", IntegerType)\n",
    "val schema = StructType(Array(ID, name, age, num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용방법\n",
    "```scala\n",
    "    - spark.read.schema(StructField).csv\n",
    "    - spark.read.schema(StructField).json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schemaPeople: org.apache.spark.sql.DataFrame = [ID: int, name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schemaPeople = spark.read.schema(schema).csv(\"data/fakefriends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- numFriends: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+----------+\n",
      "| ID|    name|age|numFriends|\n",
      "+---+--------+---+----------+\n",
      "|  0|    Will| 33|       385|\n",
      "|  1|Jean-Luc| 26|         2|\n",
      "|  2|    Hugh| 55|       221|\n",
      "|  3|  Deanna| 40|       465|\n",
      "|  4|   Quark| 68|        21|\n",
      "|  5|  Weyoun| 59|       318|\n",
      "|  6|  Gowron| 37|       220|\n",
      "|  7|    Will| 54|       307|\n",
      "|  8|  Jadzia| 38|       380|\n",
      "|  9|    Hugh| 27|       181|\n",
      "| 10|     Odo| 53|       191|\n",
      "| 11|     Ben| 57|       372|\n",
      "| 12|   Keiko| 54|       253|\n",
      "| 13|Jean-Luc| 56|       444|\n",
      "| 14|    Hugh| 43|        49|\n",
      "| 15|     Rom| 36|        49|\n",
      "| 16|  Weyoun| 22|       323|\n",
      "| 17|     Odo| 35|        13|\n",
      "| 18|Jean-Luc| 45|       455|\n",
      "| 19|  Geordi| 60|       246|\n",
      "+---+--------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaPeople.createOrReplaceTempView(\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+----------+\n",
      "| ID|    name|age|numFriends|\n",
      "+---+--------+---+----------+\n",
      "|  0|    Will| 33|       385|\n",
      "|  1|Jean-Luc| 26|         2|\n",
      "|  2|    Hugh| 55|       221|\n",
      "|  3|  Deanna| 40|       465|\n",
      "|  4|   Quark| 68|        21|\n",
      "+---+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM people limit 5\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+\n",
      "| ID| name|age|numFriends|\n",
      "+---+-----+---+----------+\n",
      "|116|  Ben| 69|        75|\n",
      "|205| Morn| 69|       236|\n",
      "| 99|Keiko| 69|       491|\n",
      "| 97|Nerys| 69|       361|\n",
      "| 62|Keiko| 69|         9|\n",
      "+---+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM people order by age desc limit 5\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teenagers: org.apache.spark.sql.DataFrame = [ID: int, name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val teenagers = spark.sql(\"SELECT * FROM people WHERE age >= 13 AND age <= 19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: Array[org.apache.spark.sql.Row] = Array([21,Miles,19,268], [52,Beverly,19,269], [54,Brunt,19,5], [106,Beverly,18,499], [115,Dukat,18,397], [133,Quark,19,265], [136,Will,19,335], [225,Elim,19,106], [304,Will,19,404], [341,Data,18,326], [366,Keiko,19,119], [373,Quark,19,272], [377,Beverly,18,418], [404,Kasidy,18,24], [409,Nog,19,267], [439,Data,18,417], [444,Keiko,18,472], [492,Dukat,19,36], [494,Kasidy,18,194])\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = teenagers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,Miles,19,268]\n",
      "[52,Beverly,19,269]\n",
      "[54,Brunt,19,5]\n",
      "[106,Beverly,18,499]\n",
      "[115,Dukat,18,397]\n",
      "[133,Quark,19,265]\n",
      "[136,Will,19,335]\n",
      "[225,Elim,19,106]\n",
      "[304,Will,19,404]\n",
      "[341,Data,18,326]\n",
      "[366,Keiko,19,119]\n",
      "[373,Quark,19,272]\n",
      "[377,Beverly,18,418]\n",
      "[404,Kasidy,18,24]\n",
      "[409,Nog,19,267]\n",
      "[439,Data,18,417]\n",
      "[444,Keiko,18,472]\n",
      "[492,Dukat,19,36]\n",
      "[494,Kasidy,18,194]\n"
     ]
    }
   ],
   "source": [
    "results.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scala-spark",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
