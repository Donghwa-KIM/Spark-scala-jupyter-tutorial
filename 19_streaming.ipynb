{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실시간으로 연산\n",
    "    - byte단위가 아닌 1초단위로 실시간 연산이 수행\n",
    "    - small RDD chunk단위로 가지고 있음\n",
    "- 저장\n",
    "    - checkpoint 존재\n",
    "- 연산\n",
    "    - Dstreaming 객체의 형태지만 RDD함수로 연산할 수 있음\n",
    "- 연산범위\n",
    "    - window operation으로 특정시점에 대한 연산이 가능\n",
    "        - e.g. reducedByWindow()\n",
    "    - 세션별로 연산이 가능\n",
    "        - e.g. updateStateByKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark._\n",
       "import org.apache.spark.SparkContext._\n",
       "import org.apache.spark.streaming._\n",
       "import org.apache.spark.streaming.StreamingContext._\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.streaming._\n",
    "import org.apache.spark.streaming.StreamingContext._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@66c6ae57\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ssc = new StreamingContext(sc, Seconds(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Terminal를 열어 아래와 같이 실행\n",
    "    - OpenBSD netcat(nc)\n",
    "    - \"-l\": Listen mode, for inbound connects\n",
    "    - \"-k\": Keep inbound sockets open for multiple connects\n",
    "    - \"5000\": port\n",
    "```bash\n",
    "nc -lk 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lines: org.apache.spark.streaming.dstream.ReceiverInputDStream[String] = org.apache.spark.streaming.dstream.SocketInputDStream@3c501c53\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//ssc.socketTextStream(\"IP address\", port)\n",
    "val lines = ssc.socketTextStream(\"localhost\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words: org.apache.spark.streaming.dstream.DStream[String] = org.apache.spark.streaming.dstream.FlatMappedDStream@788fa4fc\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = lines.flatMap(_.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.streaming.StreamingContext._\n",
       "pairs: org.apache.spark.streaming.dstream.DStream[(String, Int)] = org.apache.spark.streaming.dstream.MappedDStream@6a98c5dd\n",
       "wordCounts: org.apache.spark.streaming.dstream.DStream[(String, Int)] = org.apache.spark.streaming.dstream.ShuffledDStream@2450eaf5\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.streaming.StreamingContext._\n",
    "val pairs = words.map(word => (word, 1))\n",
    "// Reduce last 30 seconds of data, every 10 seconds\n",
    "val wordCounts = pairs.reduceByKeyAndWindow((a:Int,b:Int) => (a + b) , Seconds(30), Seconds(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()             // Start the computation\n",
    "ssc.awaitTermination()  // Wait for the computation to terminate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scala-spark",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
