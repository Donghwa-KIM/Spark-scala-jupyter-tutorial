{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter\n",
    "    - remove data from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://163.152.---.---:----\n",
       "SparkContext available as 'sc' (version = 2.3.1, master = local[*], app id = local-1553043368515)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lines: org.apache.spark.rdd.RDD[String] = ./data/1800.csv MapPartitionsRDD[1] at textFile at <console>:28\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lines = sc.textFile(\"./data/1800.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 col: Weather station\n",
    "- 2 col: Date\n",
    "- 3 col: Temperature tyoe\n",
    "- 4 col: Temperature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554,18000101,TMAX,-75,,,E,\n",
      "ITE00100554,18000101,TMIN,-148,,,E,\n",
      "GM000010962,18000101,PRCP,0,,,E,\n",
      "EZE00100082,18000101,TMAX,-86,,,E,\n",
      "EZE00100082,18000101,TMIN,-135,,,E,\n",
      "ITE00100554,18000102,TMAX,-60,,I,E,\n",
      "ITE00100554,18000102,TMIN,-125,,,E,\n",
      "GM000010962,18000102,PRCP,0,,,E,\n",
      "EZE00100082,18000102,TMAX,-44,,,E,\n",
      "EZE00100082,18000102,TMIN,-130,,,E,\n"
     ]
    }
   ],
   "source": [
    "lines.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stationID: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at map at <console>:30\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stationID = lines.map(line => line.split(\",\")(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE00100554\n",
      "ITE00100554\n",
      "GM000010962\n",
      "EZE00100082\n",
      "EZE00100082\n",
      "ITE00100554\n",
      "ITE00100554\n",
      "GM000010962\n",
      "EZE00100082\n",
      "EZE00100082\n"
     ]
    }
   ],
   "source": [
    "stationID.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entryType: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at map at <console>:30\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val entryType = lines.map(line => line.split(\",\")(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMAX\n",
      "TMIN\n",
      "PRCP\n",
      "TMAX\n",
      "TMIN\n",
      "TMAX\n",
      "TMIN\n",
      "PRCP\n",
      "TMAX\n",
      "TMIN\n"
     ]
    }
   ],
   "source": [
    "entryType.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature: org.apache.spark.rdd.RDD[Float] = MapPartitionsRDD[8] at map at <console>:30\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val temperature = lines.map(line => line.split(\",\")(3).toFloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-75.0\n",
      "-148.0\n",
      "0.0\n",
      "-86.0\n",
      "-135.0\n",
      "-60.0\n",
      "-125.0\n",
      "0.0\n",
      "-44.0\n",
      "-130.0\n"
     ]
    }
   ],
   "source": [
    "temperature.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature: org.apache.spark.rdd.RDD[Float] = MapPartitionsRDD[9] at map at <console>:30\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val temperature = lines.map(line => line.split(\",\")(3).toFloat*0.1f*(9.0f/5.0f)+32.0f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.5\n",
      "5.3600006\n",
      "32.0\n",
      "16.52\n",
      "7.700001\n",
      "21.2\n",
      "9.5\n",
      "32.0\n",
      "24.08\n",
      "8.6\n"
     ]
    }
   ],
   "source": [
    "temperature.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zip two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tmp: org.apache.spark.rdd.RDD[(String, String)] = ZippedPartitionsRDD2[86] at zip at <console>:34\n"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tmp = stationID.zip(entryType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res94: Array[(String, String)] = Array((ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP), (EZE00100082,TMAX), (EZE00100082,TMIN), (ITE00100554,TMAX), (ITE00100554,TMIN), (GM000010962,PRCP)..."
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zip multiple items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tmp: org.apache.spark.rdd.RDD[(String, String, Float)] = MapPartitionsRDD[89] at map at <console>:36\n"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tmp = stationID.zip(entryType).zip(temperature).map({ \n",
    "  case ((a,b), c) => (a,b,c)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res95: Array[(String, String, Float)] = Array((ITE00100554,TMAX,18.5), (ITE00100554,TMIN,5.3600006), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,16.52), (EZE00100082,TMIN,7.700001), (ITE00100554,TMAX,21.2), (ITE00100554,TMIN,9.5), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,24.08), (EZE00100082,TMIN,8.6), (ITE00100554,TMAX,27.86), (ITE00100554,TMIN,23.720001), (GM000010962,PRCP,32.72), (EZE00100082,TMAX,30.2), (EZE00100082,TMIN,18.86), (ITE00100554,TMAX,32.0), (ITE00100554,TMIN,29.66), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,22.1), (EZE00100082,TMIN,18.68), (ITE00100554,TMAX,33.8), (ITE00100554,TMIN,30.92), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,24.8), (EZE00100082,TMIN,21.56), (ITE00100554,TMAX,34.34), (ITE00100554,TMIN,34.34), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,24.98), (E..."
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 코드를 ()없이 표현 할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tmp: org.apache.spark.rdd.RDD[(String, String, Float)] = MapPartitionsRDD[104] at map at <console>:36\n"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tmp = stationID zip entryType zip temperature map { \n",
    "  case ((a,b), c) => (a,b,c)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res99: Array[(String, String, Float)] = Array((ITE00100554,TMAX,18.5), (ITE00100554,TMIN,5.3600006), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,16.52), (EZE00100082,TMIN,7.700001), (ITE00100554,TMAX,21.2), (ITE00100554,TMIN,9.5), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,24.08), (EZE00100082,TMIN,8.6), (ITE00100554,TMAX,27.86), (ITE00100554,TMIN,23.720001), (GM000010962,PRCP,32.72), (EZE00100082,TMAX,30.2), (EZE00100082,TMIN,18.86), (ITE00100554,TMAX,32.0), (ITE00100554,TMIN,29.66), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,22.1), (EZE00100082,TMIN,18.68), (ITE00100554,TMAX,33.8), (ITE00100554,TMIN,30.92), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,24.8), (EZE00100082,TMIN,21.56), (ITE00100554,TMAX,34.34), (ITE00100554,TMIN,34.34), (GM000010962,PRCP,32.0), (EZE00100082,TMAX,24.98), (E..."
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a function, to append pair tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parseLine: (line: String)(String, String, Float)\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parseLine(line:String) ={\n",
    "    val fields = line.split(\",\")\n",
    "    val stationID = fields(0)\n",
    "    val entryType = fields(2)\n",
    "    val temperature = fields(3).toFloat*0.1f*(9.0f/5.0f) +32.0f  // from Celslus to Fahrenheit\n",
    "    (stationID, entryType, temperature)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parsedLines: org.apache.spark.rdd.RDD[(String, String, Float)] = MapPartitionsRDD[19] at map at <console>:40\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parsedLines = lines.map(parseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ITE00100554,TMAX,18.5)\n",
      "(ITE00100554,TMIN,5.3600006)\n",
      "(GM000010962,PRCP,32.0)\n",
      "(EZE00100082,TMAX,16.52)\n",
      "(EZE00100082,TMIN,7.700001)\n",
      "(ITE00100554,TMAX,21.2)\n",
      "(ITE00100554,TMIN,9.5)\n",
      "(GM000010962,PRCP,32.0)\n",
      "(EZE00100082,TMAX,24.08)\n",
      "(EZE00100082,TMIN,8.6)\n"
     ]
    }
   ],
   "source": [
    "parsedLines.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering: mininum temperature만 고려하고 싶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minTemps: org.apache.spark.rdd.RDD[(String, String, Float)] = MapPartitionsRDD[20] at filter at <console>:42\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val minTemps = parsedLines.filter(x => x._2 == \"TMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ITE00100554,TMIN,5.3600006)\n",
      "(EZE00100082,TMIN,7.700001)\n",
      "(ITE00100554,TMIN,9.5)\n",
      "(EZE00100082,TMIN,8.6)\n",
      "(ITE00100554,TMIN,23.720001)\n",
      "(EZE00100082,TMIN,18.86)\n",
      "(ITE00100554,TMIN,29.66)\n",
      "(EZE00100082,TMIN,18.68)\n",
      "(ITE00100554,TMIN,30.92)\n",
      "(EZE00100082,TMIN,21.56)\n"
     ]
    }
   ],
   "source": [
    "minTemps.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stationTemps: org.apache.spark.rdd.RDD[(String, Float)] = MapPartitionsRDD[23] at map at <console>:44\n"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stationTemps = minTemps.map(x => (x._1, x._3.toFloat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ITE00100554,5.3600006)\n",
      "(EZE00100082,7.700001)\n",
      "(ITE00100554,9.5)\n",
      "(EZE00100082,8.6)\n",
      "(ITE00100554,23.720001)\n",
      "(EZE00100082,18.86)\n",
      "(ITE00100554,29.66)\n",
      "(EZE00100082,18.68)\n",
      "(ITE00100554,30.92)\n",
      "(EZE00100082,21.56)\n"
     ]
    }
   ],
   "source": [
    "stationTemps.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 key마다 최소값을 비교해가면서 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minTempsByStation: org.apache.spark.rdd.RDD[(String, Float)] = ShuffledRDD[26] at reduceByKey at <console>:47\n"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// first step (x,y) => min(5.36, 7.7)\n",
    "val minTempsByStation = stationTemps.reduceByKey((x,y) => math.min(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: Array[(String, Float)] = Array((EZE00100082,7.700001), (ITE00100554,5.3600006))\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = minTempsByStation.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res41: Array[(String, Float)] = Array((EZE00100082,7.700001), (ITE00100554,5.3600006))\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EZE00100082 minimum temperature: 7.700001 F\n",
      "ITE00100554 minimum temperature: 5.360001 F\n"
     ]
    }
   ],
   "source": [
    "for (result <- results.sorted){\n",
    "    val station = result._1\n",
    "    val temp = result._2\n",
    "    val formattedTemp = f\"$temp%2f F\"\n",
    "    println(s\"$station minimum temperature: $formattedTemp\")\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scala-spark",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
